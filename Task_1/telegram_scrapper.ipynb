{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API ID: 29294185, API Hash: aab7ac1b04800f8cacd9bb582779349e, Phone: +251954737771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Server closed the connection: 0 bytes read on a total of 8 expected bytes\n",
      "Server closed the connection: 0 bytes read on a total of 8 expected bytes\n",
      "Security error while unpacking a received message: Server replied with a wrong session ID (see FAQ for details)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as Abdi K; remember to not break the ToS or you will risk an account ban!\n",
      "Starting to scrape @Fashiontera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Server closed the connection: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Server closed the connection: [WinError 121] The semaphore timeout period has expired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping data from @Fashiontera\n",
      "Starting to scrape @ZemenExpress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdilala\\anaconda3\\Lib\\site-packages\\telethon\\extensions\\binaryreader.py:37: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  return int.from_bytes(self.read(4), byteorder='little', signed=signed)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping data from @ZemenExpress\n",
      "Starting to scrape @nevacomputer...\n",
      "Finished scraping data from @nevacomputer\n",
      "Starting to scrape @meneshayeofficial...\n",
      "Finished scraping data from @meneshayeofficial\n",
      "Starting to scrape @ethio_brand_collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Telegram is having internal issues TimeoutError: Timeout while fetching data (caused by GetFileRequest)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping data from @ethio_brand_collection\n"
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Read credentials from the environment\n",
    "api_id = os.getenv('TG_API_ID')\n",
    "api_hash = os.getenv('TG_API_HASH')\n",
    "phone = os.getenv('phone')\n",
    "\n",
    "# Print to verify values (optional, for debugging)\n",
    "print(f\"API ID: {api_id}, API Hash: {api_hash}, Phone: {phone}\")\n",
    "\n",
    "# Function to scrape data from a single channel\n",
    "async def scrape_channel(client, channel_username, writer, media_dir):\n",
    "    try:\n",
    "        entity = await client.get_entity(channel_username)\n",
    "        channel_title = entity.title\n",
    "        async for message in client.iter_messages(entity, limit=10000):\n",
    "            media_path = None\n",
    "            if message.media and hasattr(message.media, 'photo'):\n",
    "                filename = f\"{channel_username}_{message.id}.jpg\"\n",
    "                media_path = os.path.join(media_dir, filename)\n",
    "                try:\n",
    "                    await client.download_media(message.media, media_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to download media for message {message.id}: {e}\")\n",
    "            \n",
    "            writer.writerow([channel_title, channel_username, message.id, message.message, message.date, media_path])\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {channel_username}: {e}\")\n",
    "\n",
    "# Main function\n",
    "async def main():\n",
    "    # Initialize the client with a unique session name\n",
    "    async with TelegramClient('new_v_session', api_id, api_hash, timeout=10) as client:\n",
    "        await client.start()\n",
    "        \n",
    "        media_dir = 'photos'\n",
    "        os.makedirs(media_dir, exist_ok=True)\n",
    "\n",
    "        with open('telegram_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Channel Title', 'Channel Username', 'ID', 'Message', 'Date', 'Media Path'])\n",
    "            \n",
    "            channels = [\n",
    "                '@Fashiontera',\n",
    "                '@ZemenExpress',\n",
    "                '@nevacomputer',\n",
    "                '@meneshayeofficial',\n",
    "                '@ethio_brand_collection',\n",
    "            ]\n",
    "            \n",
    "            for channel in channels:\n",
    "                print(f\"Starting to scrape {channel}...\")\n",
    "                await scrape_channel(client, channel, writer, media_dir)\n",
    "                print(f\"Finished scraping data from {channel}\")\n",
    "\n",
    "# If running in an environment with an active event loop\n",
    "try:\n",
    "    await main()\n",
    "except RuntimeError:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
